{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (49000, 6400)\n",
      "val (1000, 6400)\n",
      "test (1000, 6400)\n"
     ]
    }
   ],
   "source": [
    "# just test the password\n",
    "import cPickle as pickle\n",
    "with open(\"features.pickle\") as f:\n",
    "    [trainXC,valXC,testXC,y_train,y_val,y_test]=pickle.load(f)\n",
    "\n",
    "print \"train\",trainXC.shape\n",
    "print \"val\",valXC.shape\n",
    "print \"test\",testXC.shape\n",
    "# In[125]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 80000: loss 2.302135\n",
      "iteration 200 / 80000: loss 2.276377\n",
      "iteration 300 / 80000: loss 1.980792\n",
      "train_acc 0.218750, val_acc 0.265000, time 0\n",
      "iteration 400 / 80000: loss 1.930451\n",
      "iteration 500 / 80000: loss 1.962754\n",
      "iteration 600 / 80000: loss 1.897155\n",
      "iteration 700 / 80000: loss 1.801479\n",
      "train_acc 0.429688, val_acc 0.398000, time 0\n",
      "iteration 800 / 80000: loss 1.668502\n",
      "iteration 900 / 80000: loss 1.594174\n",
      "iteration 1000 / 80000: loss 1.569404\n",
      "iteration 1100 / 80000: loss 1.571230\n",
      "train_acc 0.492188, val_acc 0.474000, time 0\n",
      "iteration 1200 / 80000: loss 1.530495\n",
      "iteration 1300 / 80000: loss 1.458247\n",
      "iteration 1400 / 80000: loss 1.345386\n",
      "iteration 1500 / 80000: loss 1.301452\n",
      "train_acc 0.554688, val_acc 0.513000, time 1\n",
      "iteration 1600 / 80000: loss 1.264788\n",
      "iteration 1700 / 80000: loss 1.433578\n",
      "iteration 1800 / 80000: loss 1.372105\n",
      "iteration 1900 / 80000: loss 1.272840\n",
      "train_acc 0.523438, val_acc 0.549000, time 1\n",
      "iteration 2000 / 80000: loss 1.347910\n",
      "iteration 2100 / 80000: loss 1.359860\n",
      "iteration 2200 / 80000: loss 1.400277\n",
      "train_acc 0.625000, val_acc 0.549000, time 1\n",
      "iteration 2300 / 80000: loss 1.384147\n",
      "iteration 2400 / 80000: loss 1.306202\n",
      "iteration 2500 / 80000: loss 1.198445\n",
      "iteration 2600 / 80000: loss 1.165534\n",
      "train_acc 0.617188, val_acc 0.569000, time 1\n",
      "iteration 2700 / 80000: loss 1.297953\n",
      "iteration 2800 / 80000: loss 1.323754\n",
      "iteration 2900 / 80000: loss 1.260874\n",
      "iteration 3000 / 80000: loss 1.312775\n",
      "train_acc 0.578125, val_acc 0.570000, time 2\n",
      "iteration 3100 / 80000: loss 1.286539\n",
      "iteration 3200 / 80000: loss 1.233876\n",
      "iteration 3300 / 80000: loss 1.284861\n",
      "iteration 3400 / 80000: loss 1.250643\n",
      "train_acc 0.695312, val_acc 0.583000, time 2\n",
      "iteration 3500 / 80000: loss 1.258915\n",
      "iteration 3600 / 80000: loss 1.096054\n",
      "iteration 3700 / 80000: loss 1.137487\n",
      "iteration 3800 / 80000: loss 1.162506\n",
      "train_acc 0.625000, val_acc 0.590000, time 2\n",
      "iteration 3900 / 80000: loss 1.045793\n",
      "iteration 4000 / 80000: loss 1.153653\n",
      "iteration 4100 / 80000: loss 1.162915\n",
      "iteration 4200 / 80000: loss 1.319060\n",
      "train_acc 0.593750, val_acc 0.589000, time 2\n",
      "iteration 4300 / 80000: loss 1.331883\n",
      "iteration 4400 / 80000: loss 1.214411\n",
      "iteration 4500 / 80000: loss 1.248019\n",
      "train_acc 0.703125, val_acc 0.603000, time 3\n",
      "iteration 4600 / 80000: loss 1.205274\n",
      "iteration 4700 / 80000: loss 1.118067\n",
      "iteration 4800 / 80000: loss 1.087818\n",
      "iteration 4900 / 80000: loss 1.118572\n",
      "train_acc 0.585938, val_acc 0.613000, time 3\n",
      "iteration 5000 / 80000: loss 1.096589\n",
      "iteration 5100 / 80000: loss 0.867765\n",
      "iteration 5200 / 80000: loss 1.422515\n",
      "iteration 5300 / 80000: loss 1.023690\n",
      "train_acc 0.687500, val_acc 0.601000, time 3\n",
      "iteration 5400 / 80000: loss 1.251046\n",
      "iteration 5500 / 80000: loss 1.178711\n",
      "iteration 5600 / 80000: loss 1.161989\n",
      "iteration 5700 / 80000: loss 1.099423\n",
      "train_acc 0.679688, val_acc 0.629000, time 3\n",
      "iteration 5800 / 80000: loss 1.006943\n",
      "iteration 5900 / 80000: loss 1.141147\n",
      "iteration 6000 / 80000: loss 1.117703\n",
      "iteration 6100 / 80000: loss 1.159670\n",
      "train_acc 0.679688, val_acc 0.629000, time 4\n",
      "iteration 6200 / 80000: loss 1.118953\n",
      "iteration 6300 / 80000: loss 1.109265\n",
      "iteration 6400 / 80000: loss 0.914445\n",
      "train_acc 0.617188, val_acc 0.633000, time 4\n",
      "iteration 6500 / 80000: loss 1.163015\n",
      "iteration 6600 / 80000: loss 1.166196\n",
      "iteration 6700 / 80000: loss 1.123245\n",
      "iteration 6800 / 80000: loss 1.040261\n",
      "train_acc 0.695312, val_acc 0.633000, time 4\n",
      "iteration 6900 / 80000: loss 1.168259\n",
      "iteration 7000 / 80000: loss 1.039868\n",
      "iteration 7100 / 80000: loss 1.136638\n",
      "iteration 7200 / 80000: loss 0.992458\n",
      "train_acc 0.617188, val_acc 0.630000, time 4\n",
      "iteration 7300 / 80000: loss 1.009381\n",
      "iteration 7400 / 80000: loss 1.091290\n",
      "iteration 7500 / 80000: loss 1.028164\n",
      "iteration 7600 / 80000: loss 1.205169\n",
      "train_acc 0.687500, val_acc 0.639000, time 5\n",
      "iteration 7700 / 80000: loss 1.102322\n",
      "iteration 7800 / 80000: loss 1.103701\n",
      "iteration 7900 / 80000: loss 0.870970\n",
      "iteration 8000 / 80000: loss 1.153629\n",
      "train_acc 0.687500, val_acc 0.641000, time 5\n",
      "iteration 8100 / 80000: loss 1.254831\n",
      "iteration 8200 / 80000: loss 1.024738\n",
      "iteration 8300 / 80000: loss 1.125787\n",
      "iteration 8400 / 80000: loss 1.078752\n",
      "train_acc 0.718750, val_acc 0.649000, time 5\n",
      "iteration 8500 / 80000: loss 0.975965\n",
      "iteration 8600 / 80000: loss 1.000666\n",
      "iteration 8700 / 80000: loss 0.990369\n",
      "train_acc 0.640625, val_acc 0.631000, time 5\n",
      "iteration 8800 / 80000: loss 0.930292\n",
      "iteration 8900 / 80000: loss 0.979721\n",
      "iteration 9000 / 80000: loss 1.018779\n",
      "iteration 9100 / 80000: loss 1.119888\n",
      "train_acc 0.578125, val_acc 0.641000, time 6\n",
      "iteration 9200 / 80000: loss 1.030923\n",
      "iteration 9300 / 80000: loss 0.990338\n",
      "iteration 9400 / 80000: loss 0.912321\n",
      "iteration 9500 / 80000: loss 1.083550\n",
      "train_acc 0.695312, val_acc 0.656000, time 6\n",
      "iteration 9600 / 80000: loss 0.979359\n",
      "iteration 9700 / 80000: loss 0.991620\n",
      "iteration 9800 / 80000: loss 0.970758\n",
      "iteration 9900 / 80000: loss 1.017303\n",
      "train_acc 0.687500, val_acc 0.638000, time 6\n",
      "iteration 10000 / 80000: loss 1.081892\n",
      "iteration 10100 / 80000: loss 0.900852\n",
      "iteration 10200 / 80000: loss 1.026726\n",
      "iteration 10300 / 80000: loss 1.178674\n",
      "train_acc 0.632812, val_acc 0.662000, time 6\n",
      "iteration 10400 / 80000: loss 0.889774\n",
      "iteration 10500 / 80000: loss 1.017293\n",
      "iteration 10600 / 80000: loss 1.078115\n",
      "train_acc 0.718750, val_acc 0.646000, time 7\n",
      "iteration 10700 / 80000: loss 1.002975\n",
      "iteration 10800 / 80000: loss 0.922457\n",
      "iteration 10900 / 80000: loss 1.006568\n",
      "iteration 11000 / 80000: loss 1.064606\n",
      "train_acc 0.773438, val_acc 0.654000, time 7\n",
      "iteration 11100 / 80000: loss 0.879659\n",
      "iteration 11200 / 80000: loss 0.992126\n",
      "iteration 11300 / 80000: loss 1.036240\n",
      "iteration 11400 / 80000: loss 0.898353\n",
      "train_acc 0.703125, val_acc 0.667000, time 7\n",
      "iteration 11500 / 80000: loss 1.061707\n",
      "iteration 11600 / 80000: loss 1.128824\n",
      "iteration 11700 / 80000: loss 0.941987\n",
      "iteration 11800 / 80000: loss 0.935859\n",
      "train_acc 0.757812, val_acc 0.670000, time 7\n",
      "iteration 11900 / 80000: loss 1.047089\n",
      "iteration 12000 / 80000: loss 0.989598\n",
      "iteration 12100 / 80000: loss 0.672557\n",
      "iteration 12200 / 80000: loss 1.129294\n",
      "train_acc 0.671875, val_acc 0.662000, time 8\n",
      "iteration 12300 / 80000: loss 1.119526\n",
      "iteration 12400 / 80000: loss 0.973530\n",
      "iteration 12500 / 80000: loss 0.785740\n",
      "iteration 12600 / 80000: loss 0.857575\n",
      "train_acc 0.656250, val_acc 0.669000, time 8\n",
      "iteration 12700 / 80000: loss 0.824108\n",
      "iteration 12800 / 80000: loss 1.175174\n",
      "iteration 12900 / 80000: loss 0.937492\n",
      "train_acc 0.679688, val_acc 0.677000, time 8\n",
      "iteration 13000 / 80000: loss 0.835220\n",
      "iteration 13100 / 80000: loss 0.889786\n",
      "iteration 13200 / 80000: loss 1.063316\n",
      "iteration 13300 / 80000: loss 0.987930\n",
      "train_acc 0.703125, val_acc 0.662000, time 8\n",
      "iteration 13400 / 80000: loss 1.028697\n",
      "iteration 13500 / 80000: loss 0.855590\n",
      "iteration 13600 / 80000: loss 0.878539\n",
      "iteration 13700 / 80000: loss 0.942096\n",
      "train_acc 0.726562, val_acc 0.669000, time 9\n",
      "iteration 13800 / 80000: loss 1.053280\n",
      "iteration 13900 / 80000: loss 0.929756\n",
      "iteration 14000 / 80000: loss 1.081828\n",
      "iteration 14100 / 80000: loss 0.880069\n",
      "train_acc 0.625000, val_acc 0.672000, time 9\n",
      "iteration 14200 / 80000: loss 0.846052\n",
      "iteration 14300 / 80000: loss 1.058097\n",
      "iteration 14400 / 80000: loss 1.023153\n",
      "iteration 14500 / 80000: loss 0.854325\n",
      "train_acc 0.703125, val_acc 0.672000, time 9\n",
      "iteration 14600 / 80000: loss 0.927272\n",
      "iteration 14700 / 80000: loss 0.995095\n",
      "iteration 14800 / 80000: loss 1.033062\n",
      "train_acc 0.664062, val_acc 0.670000, time 10\n",
      "iteration 14900 / 80000: loss 0.791938\n",
      "iteration 15000 / 80000: loss 1.024727\n",
      "iteration 15100 / 80000: loss 0.905052\n",
      "iteration 15200 / 80000: loss 0.987921\n",
      "train_acc 0.757812, val_acc 0.681000, time 10\n",
      "iteration 15300 / 80000: loss 0.960443\n",
      "iteration 15400 / 80000: loss 1.040048\n",
      "iteration 15500 / 80000: loss 1.053656\n",
      "iteration 15600 / 80000: loss 0.864421\n",
      "train_acc 0.640625, val_acc 0.665000, time 10\n",
      "iteration 15700 / 80000: loss 0.937750\n",
      "iteration 15800 / 80000: loss 0.918964\n",
      "iteration 15900 / 80000: loss 0.880377\n",
      "iteration 16000 / 80000: loss 0.785339\n",
      "train_acc 0.734375, val_acc 0.688000, time 10\n",
      "iteration 16100 / 80000: loss 1.095741\n",
      "iteration 16200 / 80000: loss 0.840092\n",
      "iteration 16300 / 80000: loss 1.103016\n",
      "iteration 16400 / 80000: loss 1.073710\n",
      "train_acc 0.679688, val_acc 0.672000, time 11\n",
      "iteration 16500 / 80000: loss 1.069457\n",
      "iteration 16600 / 80000: loss 0.912660\n",
      "iteration 16700 / 80000: loss 0.879401\n",
      "iteration 16800 / 80000: loss 0.952694\n",
      "train_acc 0.679688, val_acc 0.683000, time 11\n",
      "iteration 16900 / 80000: loss 0.897562\n",
      "iteration 17000 / 80000: loss 0.953318\n",
      "iteration 17100 / 80000: loss 0.966771\n",
      "train_acc 0.710938, val_acc 0.679000, time 11\n",
      "iteration 17200 / 80000: loss 0.737167\n",
      "iteration 17300 / 80000: loss 1.079485\n",
      "iteration 17400 / 80000: loss 0.868727\n",
      "iteration 17500 / 80000: loss 0.890315\n",
      "train_acc 0.726562, val_acc 0.684000, time 11\n",
      "iteration 17600 / 80000: loss 0.963236\n",
      "iteration 17700 / 80000: loss 0.949955\n",
      "iteration 17800 / 80000: loss 0.862955\n",
      "iteration 17900 / 80000: loss 0.863530\n",
      "train_acc 0.765625, val_acc 0.698000, time 12\n",
      "iteration 18000 / 80000: loss 0.814179\n",
      "iteration 18100 / 80000: loss 0.976149\n",
      "iteration 18200 / 80000: loss 0.952155\n",
      "iteration 18300 / 80000: loss 0.980648\n",
      "train_acc 0.789062, val_acc 0.698000, time 12\n",
      "iteration 18400 / 80000: loss 0.933244\n",
      "iteration 18500 / 80000: loss 0.918173\n",
      "iteration 18600 / 80000: loss 0.910016\n",
      "iteration 18700 / 80000: loss 0.984971\n",
      "train_acc 0.703125, val_acc 0.705000, time 12\n",
      "iteration 18800 / 80000: loss 0.836163\n",
      "iteration 18900 / 80000: loss 0.864686\n",
      "iteration 19000 / 80000: loss 0.950309\n",
      "iteration 19100 / 80000: loss 0.752879\n",
      "train_acc 0.773438, val_acc 0.697000, time 12\n",
      "iteration 19200 / 80000: loss 0.805364\n",
      "iteration 19300 / 80000: loss 0.856617\n",
      "iteration 19400 / 80000: loss 0.793492\n",
      "train_acc 0.679688, val_acc 0.690000, time 13\n",
      "iteration 19500 / 80000: loss 0.851276\n",
      "iteration 19600 / 80000: loss 0.760896\n",
      "iteration 19700 / 80000: loss 0.942687\n",
      "iteration 19800 / 80000: loss 0.991809\n",
      "train_acc 0.734375, val_acc 0.706000, time 13\n",
      "iteration 19900 / 80000: loss 0.898257\n",
      "iteration 20000 / 80000: loss 1.008710\n",
      "iteration 20100 / 80000: loss 0.883266\n",
      "iteration 20200 / 80000: loss 0.782662\n",
      "train_acc 0.718750, val_acc 0.682000, time 13\n",
      "iteration 20300 / 80000: loss 0.876681\n",
      "iteration 20400 / 80000: loss 0.797578\n",
      "iteration 20500 / 80000: loss 0.768491\n",
      "iteration 20600 / 80000: loss 0.932626\n",
      "train_acc 0.718750, val_acc 0.683000, time 13\n",
      "iteration 20700 / 80000: loss 0.715360\n",
      "iteration 20800 / 80000: loss 0.975952\n",
      "iteration 20900 / 80000: loss 0.864960\n",
      "iteration 21000 / 80000: loss 0.821960\n",
      "train_acc 0.734375, val_acc 0.694000, time 14\n",
      "iteration 21100 / 80000: loss 0.915911\n",
      "iteration 21200 / 80000: loss 0.805854\n",
      "iteration 21300 / 80000: loss 0.905536\n",
      "train_acc 0.757812, val_acc 0.700000, time 14\n",
      "iteration 21400 / 80000: loss 0.814733\n",
      "iteration 21500 / 80000: loss 0.922562\n",
      "iteration 21600 / 80000: loss 0.880176\n",
      "iteration 21700 / 80000: loss 0.986950\n",
      "train_acc 0.726562, val_acc 0.697000, time 14\n",
      "iteration 21800 / 80000: loss 0.933428\n",
      "iteration 21900 / 80000: loss 0.735387\n",
      "iteration 22000 / 80000: loss 0.888666\n",
      "iteration 22100 / 80000: loss 0.951364\n",
      "train_acc 0.687500, val_acc 0.702000, time 15\n",
      "iteration 22200 / 80000: loss 0.836272\n",
      "iteration 22300 / 80000: loss 0.745983\n",
      "iteration 22400 / 80000: loss 1.005081\n",
      "iteration 22500 / 80000: loss 0.918017\n",
      "train_acc 0.726562, val_acc 0.704000, time 15\n",
      "iteration 22600 / 80000: loss 0.870586\n",
      "iteration 22700 / 80000: loss 0.986281\n",
      "iteration 22800 / 80000: loss 1.040065\n",
      "iteration 22900 / 80000: loss 0.710789\n",
      "train_acc 0.718750, val_acc 0.709000, time 15\n",
      "iteration 23000 / 80000: loss 0.851509\n",
      "iteration 23100 / 80000: loss 0.761904\n",
      "iteration 23200 / 80000: loss 0.788112\n",
      "iteration 23300 / 80000: loss 0.842374\n",
      "train_acc 0.726562, val_acc 0.696000, time 15\n",
      "iteration 23400 / 80000: loss 0.840946\n",
      "iteration 23500 / 80000: loss 1.062854\n",
      "iteration 23600 / 80000: loss 0.878932\n",
      "train_acc 0.726562, val_acc 0.706000, time 16\n",
      "iteration 23700 / 80000: loss 0.913618\n",
      "iteration 23800 / 80000: loss 1.010087\n",
      "iteration 23900 / 80000: loss 0.647571\n",
      "iteration 24000 / 80000: loss 0.876300\n",
      "train_acc 0.734375, val_acc 0.714000, time 16\n",
      "iteration 24100 / 80000: loss 0.713230\n",
      "iteration 24200 / 80000: loss 0.887957\n",
      "iteration 24300 / 80000: loss 0.840118\n",
      "iteration 24400 / 80000: loss 0.927498\n",
      "train_acc 0.726562, val_acc 0.707000, time 16\n",
      "iteration 24500 / 80000: loss 0.808772\n",
      "iteration 24600 / 80000: loss 0.920876\n",
      "iteration 24700 / 80000: loss 0.864546\n",
      "iteration 24800 / 80000: loss 0.926561\n",
      "train_acc 0.703125, val_acc 0.705000, time 16\n",
      "iteration 24900 / 80000: loss 0.717705\n",
      "iteration 25000 / 80000: loss 0.747418\n",
      "iteration 25100 / 80000: loss 0.754431\n",
      "iteration 25200 / 80000: loss 0.927589\n",
      "train_acc 0.734375, val_acc 0.707000, time 17\n",
      "iteration 25300 / 80000: loss 0.872019\n",
      "iteration 25400 / 80000: loss 0.937657\n",
      "iteration 25500 / 80000: loss 0.778642\n",
      "train_acc 0.765625, val_acc 0.704000, time 17\n",
      "iteration 25600 / 80000: loss 0.712497\n",
      "iteration 25700 / 80000: loss 1.041769\n",
      "iteration 25800 / 80000: loss 0.732464\n",
      "iteration 25900 / 80000: loss 0.887372\n",
      "train_acc 0.656250, val_acc 0.709000, time 17\n",
      "iteration 26000 / 80000: loss 0.821222\n",
      "iteration 26100 / 80000: loss 0.841982\n",
      "iteration 26200 / 80000: loss 0.870421\n",
      "iteration 26300 / 80000: loss 0.976784\n",
      "train_acc 0.710938, val_acc 0.689000, time 18\n",
      "iteration 26400 / 80000: loss 0.931230\n",
      "iteration 26500 / 80000: loss 0.813200\n",
      "iteration 26600 / 80000: loss 0.777719\n",
      "iteration 26700 / 80000: loss 0.797286\n",
      "train_acc 0.734375, val_acc 0.703000, time 18\n",
      "iteration 26800 / 80000: loss 0.784156\n",
      "iteration 26900 / 80000: loss 0.891896\n",
      "iteration 27000 / 80000: loss 0.797216\n",
      "iteration 27100 / 80000: loss 0.807907\n",
      "train_acc 0.703125, val_acc 0.714000, time 18\n",
      "iteration 27200 / 80000: loss 0.958332\n",
      "iteration 27300 / 80000: loss 0.811251\n",
      "iteration 27400 / 80000: loss 0.956117\n",
      "iteration 27500 / 80000: loss 0.741077\n",
      "train_acc 0.710938, val_acc 0.710000, time 18\n",
      "iteration 27600 / 80000: loss 0.868095\n",
      "iteration 27700 / 80000: loss 1.027510\n",
      "iteration 27800 / 80000: loss 0.743789\n",
      "train_acc 0.750000, val_acc 0.705000, time 19\n",
      "iteration 27900 / 80000: loss 0.697927\n",
      "iteration 28000 / 80000: loss 0.825559\n",
      "iteration 28100 / 80000: loss 0.845234\n",
      "iteration 28200 / 80000: loss 0.931771\n",
      "train_acc 0.710938, val_acc 0.717000, time 19\n",
      "iteration 28300 / 80000: loss 0.779702\n",
      "iteration 28400 / 80000: loss 0.898621\n",
      "iteration 28500 / 80000: loss 0.822007\n",
      "iteration 28600 / 80000: loss 0.815964\n",
      "train_acc 0.765625, val_acc 0.723000, time 19\n",
      "iteration 28700 / 80000: loss 0.911979\n",
      "iteration 28800 / 80000: loss 0.807757\n",
      "iteration 28900 / 80000: loss 0.865709\n",
      "iteration 29000 / 80000: loss 0.746554\n",
      "train_acc 0.765625, val_acc 0.707000, time 19\n",
      "iteration 29100 / 80000: loss 0.664384\n",
      "iteration 29200 / 80000: loss 0.817218\n",
      "iteration 29300 / 80000: loss 0.781309\n",
      "iteration 29400 / 80000: loss 0.838429\n",
      "train_acc 0.750000, val_acc 0.713000, time 20\n",
      "iteration 29500 / 80000: loss 1.020099\n",
      "iteration 29600 / 80000: loss 0.717607\n",
      "iteration 29700 / 80000: loss 0.834347\n",
      "train_acc 0.742188, val_acc 0.718000, time 20\n",
      "iteration 29800 / 80000: loss 0.799227\n",
      "iteration 29900 / 80000: loss 0.833088\n",
      "iteration 30000 / 80000: loss 1.075452\n",
      "iteration 30100 / 80000: loss 0.935772\n",
      "train_acc 0.750000, val_acc 0.705000, time 20\n",
      "iteration 30200 / 80000: loss 0.856134\n",
      "iteration 30300 / 80000: loss 0.826529\n",
      "iteration 30400 / 80000: loss 0.868472\n",
      "iteration 30500 / 80000: loss 0.828671\n",
      "train_acc 0.765625, val_acc 0.712000, time 20\n",
      "iteration 30600 / 80000: loss 0.744880\n",
      "iteration 30700 / 80000: loss 0.841474\n",
      "iteration 30800 / 80000: loss 0.961015\n",
      "iteration 30900 / 80000: loss 0.680036\n",
      "train_acc 0.789062, val_acc 0.715000, time 21\n",
      "iteration 31000 / 80000: loss 0.808587\n",
      "iteration 31100 / 80000: loss 1.046537\n",
      "iteration 31200 / 80000: loss 0.666944\n",
      "iteration 31300 / 80000: loss 0.690887\n",
      "train_acc 0.757812, val_acc 0.704000, time 21\n",
      "iteration 31400 / 80000: loss 0.855297\n",
      "iteration 31500 / 80000: loss 0.810013\n",
      "iteration 31600 / 80000: loss 0.969762\n",
      "iteration 31700 / 80000: loss 0.867156\n",
      "train_acc 0.726562, val_acc 0.715000, time 21\n",
      "iteration 31800 / 80000: loss 0.789131\n",
      "iteration 31900 / 80000: loss 0.830691\n",
      "iteration 32000 / 80000: loss 0.821391\n",
      "train_acc 0.835938, val_acc 0.707000, time 22\n",
      "iteration 32100 / 80000: loss 0.853956\n",
      "iteration 32200 / 80000: loss 0.763312\n",
      "iteration 32300 / 80000: loss 0.668868\n",
      "iteration 32400 / 80000: loss 0.849134\n",
      "train_acc 0.726562, val_acc 0.723000, time 22\n",
      "iteration 32500 / 80000: loss 0.951214\n",
      "iteration 32600 / 80000: loss 0.760488\n",
      "iteration 32700 / 80000: loss 0.721203\n",
      "iteration 32800 / 80000: loss 0.810430\n",
      "train_acc 0.750000, val_acc 0.714000, time 22\n",
      "iteration 32900 / 80000: loss 0.750471\n",
      "iteration 33000 / 80000: loss 0.738099\n",
      "iteration 33100 / 80000: loss 0.802107\n",
      "iteration 33200 / 80000: loss 0.716028\n",
      "train_acc 0.773438, val_acc 0.734000, time 22\n",
      "iteration 33300 / 80000: loss 0.909198\n",
      "iteration 33400 / 80000: loss 0.779996\n",
      "iteration 33500 / 80000: loss 0.818767\n",
      "iteration 33600 / 80000: loss 1.031508\n",
      "train_acc 0.765625, val_acc 0.710000, time 23\n",
      "iteration 33700 / 80000: loss 0.702696\n",
      "iteration 33800 / 80000: loss 0.663957\n",
      "iteration 33900 / 80000: loss 0.919993\n",
      "train_acc 0.734375, val_acc 0.715000, time 23\n",
      "iteration 34000 / 80000: loss 0.803582\n",
      "iteration 34100 / 80000: loss 0.635262\n",
      "iteration 34200 / 80000: loss 0.847775\n",
      "iteration 34300 / 80000: loss 0.745147\n",
      "train_acc 0.812500, val_acc 0.706000, time 23\n",
      "iteration 34400 / 80000: loss 0.722936\n",
      "iteration 34500 / 80000: loss 0.940491\n",
      "iteration 34600 / 80000: loss 0.757494\n",
      "iteration 34700 / 80000: loss 0.763326\n",
      "train_acc 0.773438, val_acc 0.705000, time 23\n",
      "iteration 34800 / 80000: loss 0.784879\n",
      "iteration 34900 / 80000: loss 0.906762\n",
      "iteration 35000 / 80000: loss 0.826203\n",
      "iteration 35100 / 80000: loss 0.723663\n",
      "train_acc 0.843750, val_acc 0.715000, time 24\n",
      "iteration 35200 / 80000: loss 0.730401\n",
      "iteration 35300 / 80000: loss 0.806874\n",
      "iteration 35400 / 80000: loss 0.840068\n",
      "iteration 35500 / 80000: loss 0.926168\n",
      "train_acc 0.734375, val_acc 0.723000, time 24\n",
      "iteration 35600 / 80000: loss 0.766882\n",
      "iteration 35700 / 80000: loss 0.683627\n",
      "iteration 35800 / 80000: loss 0.891149\n",
      "iteration 35900 / 80000: loss 0.694147\n",
      "train_acc 0.750000, val_acc 0.721000, time 24\n",
      "iteration 36000 / 80000: loss 0.958431\n",
      "iteration 36100 / 80000: loss 0.871871\n",
      "iteration 36200 / 80000: loss 0.915435\n",
      "train_acc 0.867188, val_acc 0.714000, time 24\n",
      "iteration 36300 / 80000: loss 0.727742\n",
      "iteration 36400 / 80000: loss 0.787370\n",
      "iteration 36500 / 80000: loss 0.881493\n",
      "iteration 36600 / 80000: loss 0.867453\n",
      "train_acc 0.765625, val_acc 0.722000, time 25\n",
      "iteration 36700 / 80000: loss 0.738140\n",
      "iteration 36800 / 80000: loss 0.867969\n",
      "iteration 36900 / 80000: loss 0.762523\n",
      "iteration 37000 / 80000: loss 0.843865\n",
      "train_acc 0.687500, val_acc 0.729000, time 25\n",
      "iteration 37100 / 80000: loss 1.068718\n",
      "iteration 37200 / 80000: loss 0.766345\n",
      "iteration 37300 / 80000: loss 0.797754\n",
      "iteration 37400 / 80000: loss 0.734599\n",
      "train_acc 0.750000, val_acc 0.728000, time 25\n",
      "iteration 37500 / 80000: loss 0.895342\n",
      "iteration 37600 / 80000: loss 0.854051\n",
      "iteration 37700 / 80000: loss 1.018861\n",
      "iteration 37800 / 80000: loss 0.723012\n",
      "train_acc 0.757812, val_acc 0.724000, time 25\n",
      "iteration 37900 / 80000: loss 0.731040\n",
      "iteration 38000 / 80000: loss 0.637253\n",
      "iteration 38100 / 80000: loss 0.781590\n",
      "iteration 38200 / 80000: loss 0.758658\n",
      "train_acc 0.773438, val_acc 0.713000, time 26\n",
      "iteration 38300 / 80000: loss 0.909202\n",
      "iteration 38400 / 80000: loss 0.878005\n",
      "iteration 38500 / 80000: loss 0.810007\n",
      "train_acc 0.804688, val_acc 0.711000, time 26\n",
      "iteration 38600 / 80000: loss 0.863009\n",
      "iteration 38700 / 80000: loss 0.930229\n",
      "iteration 38800 / 80000: loss 0.738784\n",
      "iteration 38900 / 80000: loss 0.883433\n",
      "train_acc 0.765625, val_acc 0.719000, time 26\n",
      "iteration 39000 / 80000: loss 0.673824\n",
      "iteration 39100 / 80000: loss 0.796396\n",
      "iteration 39200 / 80000: loss 0.874853\n",
      "iteration 39300 / 80000: loss 0.788055\n",
      "train_acc 0.789062, val_acc 0.719000, time 27\n",
      "iteration 39400 / 80000: loss 0.696451\n",
      "iteration 39500 / 80000: loss 0.794183\n",
      "iteration 39600 / 80000: loss 0.685613\n",
      "iteration 39700 / 80000: loss 0.804226\n",
      "train_acc 0.734375, val_acc 0.711000, time 27\n",
      "iteration 39800 / 80000: loss 0.784526\n",
      "iteration 39900 / 80000: loss 0.789710\n",
      "iteration 40000 / 80000: loss 0.828104\n",
      "iteration 40100 / 80000: loss 0.700126\n",
      "train_acc 0.773438, val_acc 0.727000, time 27\n",
      "iteration 40200 / 80000: loss 0.875995\n",
      "iteration 40300 / 80000: loss 0.845312\n",
      "iteration 40400 / 80000: loss 0.803201\n",
      "train_acc 0.734375, val_acc 0.719000, time 27\n",
      "iteration 40500 / 80000: loss 0.842386\n",
      "iteration 40600 / 80000: loss 0.853093\n",
      "iteration 40700 / 80000: loss 0.873830\n",
      "iteration 40800 / 80000: loss 0.779563\n",
      "train_acc 0.750000, val_acc 0.724000, time 28\n",
      "iteration 40900 / 80000: loss 0.831927\n",
      "iteration 41000 / 80000: loss 0.692148\n",
      "iteration 41100 / 80000: loss 0.887546\n",
      "iteration 41200 / 80000: loss 0.817992\n",
      "train_acc 0.789062, val_acc 0.722000, time 28\n",
      "iteration 41300 / 80000: loss 0.749647\n",
      "iteration 41400 / 80000: loss 0.995719\n",
      "iteration 41500 / 80000: loss 0.871647\n",
      "iteration 41600 / 80000: loss 0.840628\n",
      "train_acc 0.757812, val_acc 0.727000, time 28\n",
      "iteration 41700 / 80000: loss 0.752481\n",
      "iteration 41800 / 80000: loss 0.591145\n",
      "iteration 41900 / 80000: loss 0.653459\n",
      "iteration 42000 / 80000: loss 0.823637\n",
      "train_acc 0.765625, val_acc 0.722000, time 28\n",
      "iteration 42100 / 80000: loss 0.846679\n",
      "iteration 42200 / 80000: loss 0.796915\n",
      "iteration 42300 / 80000: loss 0.847093\n",
      "iteration 42400 / 80000: loss 0.715539\n",
      "train_acc 0.765625, val_acc 0.727000, time 29\n",
      "iteration 42500 / 80000: loss 0.943195\n",
      "iteration 42600 / 80000: loss 0.799805\n",
      "iteration 42700 / 80000: loss 0.679989\n",
      "train_acc 0.718750, val_acc 0.721000, time 29\n",
      "iteration 42800 / 80000: loss 0.848354\n",
      "iteration 42900 / 80000: loss 0.749115\n",
      "iteration 43000 / 80000: loss 0.783257\n",
      "iteration 43100 / 80000: loss 0.639445\n",
      "train_acc 0.726562, val_acc 0.727000, time 29\n",
      "iteration 43200 / 80000: loss 0.829313\n",
      "iteration 43300 / 80000: loss 0.663901\n",
      "iteration 43400 / 80000: loss 0.725700\n",
      "iteration 43500 / 80000: loss 0.856615\n",
      "train_acc 0.789062, val_acc 0.721000, time 29\n",
      "iteration 43600 / 80000: loss 0.895958\n",
      "iteration 43700 / 80000: loss 0.812548\n",
      "iteration 43800 / 80000: loss 0.664045\n",
      "iteration 43900 / 80000: loss 0.775030\n",
      "train_acc 0.820312, val_acc 0.733000, time 30\n",
      "iteration 44000 / 80000: loss 0.704995\n",
      "iteration 44100 / 80000: loss 0.944035\n",
      "iteration 44200 / 80000: loss 0.757402\n",
      "iteration 44300 / 80000: loss 1.002671\n",
      "train_acc 0.750000, val_acc 0.723000, time 30\n",
      "iteration 44400 / 80000: loss 0.843074\n",
      "iteration 44500 / 80000: loss 0.822422\n",
      "iteration 44600 / 80000: loss 0.614107\n",
      "train_acc 0.773438, val_acc 0.719000, time 30\n",
      "iteration 44700 / 80000: loss 0.701909\n",
      "iteration 44800 / 80000: loss 0.679015\n",
      "iteration 44900 / 80000: loss 0.712556\n",
      "iteration 45000 / 80000: loss 0.672724\n",
      "train_acc 0.796875, val_acc 0.731000, time 31\n",
      "iteration 45100 / 80000: loss 0.485873\n",
      "iteration 45200 / 80000: loss 0.749786\n",
      "iteration 45300 / 80000: loss 0.816050\n",
      "iteration 45400 / 80000: loss 0.818584\n",
      "train_acc 0.804688, val_acc 0.736000, time 31\n",
      "iteration 45500 / 80000: loss 0.613822\n",
      "iteration 45600 / 80000: loss 0.786168\n",
      "iteration 45700 / 80000: loss 0.657290\n",
      "iteration 45800 / 80000: loss 0.829181\n",
      "train_acc 0.742188, val_acc 0.723000, time 31\n",
      "iteration 45900 / 80000: loss 0.907058\n",
      "iteration 46000 / 80000: loss 0.767477\n",
      "iteration 46100 / 80000: loss 0.890559\n",
      "iteration 46200 / 80000: loss 0.810761\n",
      "train_acc 0.781250, val_acc 0.729000, time 31\n",
      "iteration 46300 / 80000: loss 0.663325\n",
      "iteration 46400 / 80000: loss 0.640825\n",
      "iteration 46500 / 80000: loss 0.946329\n",
      "iteration 46600 / 80000: loss 0.780537\n",
      "train_acc 0.781250, val_acc 0.729000, time 32\n",
      "iteration 46700 / 80000: loss 0.734191\n",
      "iteration 46800 / 80000: loss 0.827641\n",
      "iteration 46900 / 80000: loss 0.775302\n",
      "train_acc 0.734375, val_acc 0.726000, time 32\n",
      "iteration 47000 / 80000: loss 0.816441\n",
      "iteration 47100 / 80000: loss 0.661111\n",
      "iteration 47200 / 80000: loss 0.541998\n",
      "iteration 47300 / 80000: loss 0.737193\n",
      "train_acc 0.757812, val_acc 0.732000, time 32\n",
      "iteration 47400 / 80000: loss 0.825291\n",
      "iteration 47500 / 80000: loss 0.633362\n",
      "iteration 47600 / 80000: loss 0.681705\n",
      "iteration 47700 / 80000: loss 0.931605\n",
      "train_acc 0.828125, val_acc 0.722000, time 32\n",
      "iteration 47800 / 80000: loss 0.729931\n",
      "iteration 47900 / 80000: loss 0.795037\n",
      "iteration 48000 / 80000: loss 0.785562\n",
      "iteration 48100 / 80000: loss 0.869365\n",
      "train_acc 0.796875, val_acc 0.728000, time 33\n",
      "iteration 48200 / 80000: loss 0.663959\n",
      "iteration 48300 / 80000: loss 0.643915\n",
      "iteration 48400 / 80000: loss 0.770846\n",
      "iteration 48500 / 80000: loss 0.615739\n",
      "train_acc 0.750000, val_acc 0.730000, time 33\n",
      "iteration 48600 / 80000: loss 0.829465\n",
      "iteration 48700 / 80000: loss 0.665490\n",
      "iteration 48800 / 80000: loss 0.697273\n",
      "train_acc 0.804688, val_acc 0.736000, time 33\n",
      "iteration 48900 / 80000: loss 0.683574\n",
      "iteration 49000 / 80000: loss 0.704612\n",
      "iteration 49100 / 80000: loss 0.979874\n",
      "iteration 49200 / 80000: loss 0.625300\n",
      "train_acc 0.828125, val_acc 0.730000, time 33\n",
      "iteration 49300 / 80000: loss 0.861198\n",
      "iteration 49400 / 80000: loss 0.741430\n",
      "iteration 49500 / 80000: loss 0.769511\n",
      "iteration 49600 / 80000: loss 0.733230\n",
      "train_acc 0.773438, val_acc 0.730000, time 34\n",
      "iteration 49700 / 80000: loss 0.631134\n",
      "iteration 49800 / 80000: loss 0.766122\n",
      "iteration 49900 / 80000: loss 0.785093\n",
      "iteration 50000 / 80000: loss 0.694118\n",
      "train_acc 0.765625, val_acc 0.730000, time 34\n",
      "iteration 50100 / 80000: loss 0.684451\n",
      "iteration 50200 / 80000: loss 0.727669\n",
      "iteration 50300 / 80000: loss 0.804217\n",
      "iteration 50400 / 80000: loss 0.658368\n",
      "train_acc 0.765625, val_acc 0.730000, time 34\n",
      "iteration 50500 / 80000: loss 0.760402\n",
      "iteration 50600 / 80000: loss 0.746315\n",
      "iteration 50700 / 80000: loss 0.739921\n",
      "iteration 50800 / 80000: loss 0.668170\n",
      "train_acc 0.726562, val_acc 0.730000, time 35\n",
      "iteration 50900 / 80000: loss 0.767723\n",
      "iteration 51000 / 80000: loss 0.688229\n",
      "iteration 51100 / 80000: loss 0.699407\n",
      "train_acc 0.765625, val_acc 0.731000, time 35\n",
      "iteration 51200 / 80000: loss 0.891500\n",
      "iteration 51300 / 80000: loss 0.728035\n",
      "iteration 51400 / 80000: loss 0.740119\n",
      "iteration 51500 / 80000: loss 0.794959\n",
      "train_acc 0.804688, val_acc 0.714000, time 35\n",
      "iteration 51600 / 80000: loss 0.783150\n",
      "iteration 51700 / 80000: loss 0.752023\n",
      "iteration 51800 / 80000: loss 0.626182\n",
      "iteration 51900 / 80000: loss 0.766215\n",
      "train_acc 0.843750, val_acc 0.726000, time 35\n",
      "iteration 52000 / 80000: loss 0.696812\n",
      "iteration 52100 / 80000: loss 0.781112\n",
      "iteration 52200 / 80000: loss 0.759446\n",
      "iteration 52300 / 80000: loss 0.823090\n",
      "train_acc 0.718750, val_acc 0.737000, time 36\n",
      "iteration 52400 / 80000: loss 0.770202\n",
      "iteration 52500 / 80000: loss 0.767483\n",
      "iteration 52600 / 80000: loss 0.718976\n",
      "iteration 52700 / 80000: loss 0.745847\n",
      "train_acc 0.812500, val_acc 0.732000, time 36\n",
      "iteration 52800 / 80000: loss 0.701751\n",
      "iteration 52900 / 80000: loss 0.797187\n",
      "iteration 53000 / 80000: loss 0.705459\n",
      "train_acc 0.820312, val_acc 0.728000, time 36\n",
      "iteration 53100 / 80000: loss 0.616836\n",
      "iteration 53200 / 80000: loss 0.818652\n",
      "iteration 53300 / 80000: loss 0.685110\n",
      "iteration 53400 / 80000: loss 0.861514\n",
      "train_acc 0.812500, val_acc 0.728000, time 37\n",
      "iteration 53500 / 80000: loss 0.783432\n",
      "iteration 53600 / 80000: loss 0.610871\n",
      "iteration 53700 / 80000: loss 0.921474\n",
      "iteration 53800 / 80000: loss 0.774250\n",
      "train_acc 0.773438, val_acc 0.729000, time 37\n",
      "iteration 53900 / 80000: loss 0.688467\n",
      "iteration 54000 / 80000: loss 0.826892\n",
      "iteration 54100 / 80000: loss 0.652795\n",
      "iteration 54200 / 80000: loss 0.865748\n",
      "train_acc 0.757812, val_acc 0.729000, time 37\n",
      "iteration 54300 / 80000: loss 0.795437\n",
      "iteration 54400 / 80000: loss 0.724607\n",
      "iteration 54500 / 80000: loss 0.696600\n",
      "iteration 54600 / 80000: loss 0.791112\n",
      "train_acc 0.765625, val_acc 0.742000, time 37\n",
      "iteration 54700 / 80000: loss 0.635256\n",
      "iteration 54800 / 80000: loss 0.686030\n",
      "iteration 54900 / 80000: loss 0.688005\n",
      "iteration 55000 / 80000: loss 0.715793\n",
      "train_acc 0.796875, val_acc 0.735000, time 38\n",
      "iteration 55100 / 80000: loss 0.731688\n",
      "iteration 55200 / 80000: loss 0.651670\n",
      "iteration 55300 / 80000: loss 0.689063\n",
      "train_acc 0.765625, val_acc 0.731000, time 38\n",
      "iteration 55400 / 80000: loss 0.711126\n",
      "iteration 55500 / 80000: loss 0.799952\n",
      "iteration 55600 / 80000: loss 0.748409\n",
      "iteration 55700 / 80000: loss 0.550050\n",
      "train_acc 0.851562, val_acc 0.735000, time 38\n",
      "iteration 55800 / 80000: loss 0.720988\n",
      "iteration 55900 / 80000: loss 0.699419\n",
      "iteration 56000 / 80000: loss 0.720039\n",
      "iteration 56100 / 80000: loss 0.720604\n",
      "train_acc 0.742188, val_acc 0.733000, time 38\n",
      "iteration 56200 / 80000: loss 0.827812\n",
      "iteration 56300 / 80000: loss 0.809455\n",
      "iteration 56400 / 80000: loss 0.603254\n",
      "iteration 56500 / 80000: loss 0.776094\n",
      "train_acc 0.820312, val_acc 0.732000, time 39\n",
      "iteration 56600 / 80000: loss 0.542234\n",
      "iteration 56700 / 80000: loss 0.712983\n",
      "iteration 56800 / 80000: loss 0.708423\n",
      "iteration 56900 / 80000: loss 0.675422\n",
      "train_acc 0.789062, val_acc 0.738000, time 39\n",
      "iteration 57000 / 80000: loss 0.782971\n",
      "iteration 57100 / 80000: loss 0.711685\n",
      "iteration 57200 / 80000: loss 0.613474\n",
      "iteration 57300 / 80000: loss 0.628438\n",
      "train_acc 0.828125, val_acc 0.736000, time 39\n",
      "iteration 57400 / 80000: loss 0.790214\n",
      "iteration 57500 / 80000: loss 0.635453\n",
      "iteration 57600 / 80000: loss 0.896503\n",
      "train_acc 0.812500, val_acc 0.726000, time 39\n",
      "iteration 57700 / 80000: loss 0.784579\n",
      "iteration 57800 / 80000: loss 0.702064\n",
      "iteration 57900 / 80000: loss 0.566528\n",
      "iteration 58000 / 80000: loss 0.619751\n",
      "train_acc 0.781250, val_acc 0.732000, time 40\n",
      "iteration 58100 / 80000: loss 0.719234\n",
      "iteration 58200 / 80000: loss 0.764209\n",
      "iteration 58300 / 80000: loss 0.710170\n",
      "iteration 58400 / 80000: loss 0.744473\n",
      "train_acc 0.828125, val_acc 0.728000, time 40\n",
      "iteration 58500 / 80000: loss 0.689205\n",
      "iteration 58600 / 80000: loss 0.711655\n",
      "iteration 58700 / 80000: loss 0.656293\n",
      "iteration 58800 / 80000: loss 0.665323\n",
      "train_acc 0.812500, val_acc 0.731000, time 40\n",
      "iteration 58900 / 80000: loss 0.903781\n",
      "iteration 59000 / 80000: loss 0.642084\n",
      "iteration 59100 / 80000: loss 0.671526\n",
      "iteration 59200 / 80000: loss 0.941768\n",
      "train_acc 0.796875, val_acc 0.728000, time 41\n",
      "iteration 59300 / 80000: loss 0.631971\n",
      "iteration 59400 / 80000: loss 0.634236\n",
      "iteration 59500 / 80000: loss 0.791421\n",
      "train_acc 0.781250, val_acc 0.727000, time 41\n",
      "iteration 59600 / 80000: loss 0.651834\n",
      "iteration 59700 / 80000: loss 0.683406\n",
      "iteration 59800 / 80000: loss 0.724456\n",
      "iteration 59900 / 80000: loss 0.677127\n",
      "train_acc 0.789062, val_acc 0.726000, time 41\n",
      "iteration 60000 / 80000: loss 0.691910\n",
      "iteration 60100 / 80000: loss 0.681605\n",
      "iteration 60200 / 80000: loss 0.727488\n",
      "iteration 60300 / 80000: loss 0.618775\n",
      "train_acc 0.789062, val_acc 0.740000, time 41\n",
      "iteration 60400 / 80000: loss 0.687781\n",
      "iteration 60500 / 80000: loss 0.839692\n",
      "iteration 60600 / 80000: loss 0.754965\n",
      "iteration 60700 / 80000: loss 0.819942\n",
      "train_acc 0.781250, val_acc 0.733000, time 42\n",
      "iteration 60800 / 80000: loss 0.581448\n",
      "iteration 60900 / 80000: loss 0.608915\n",
      "iteration 61000 / 80000: loss 0.773636\n",
      "iteration 61100 / 80000: loss 0.810308\n",
      "train_acc 0.789062, val_acc 0.740000, time 42\n",
      "iteration 61200 / 80000: loss 0.710314\n",
      "iteration 61300 / 80000: loss 0.596981\n",
      "iteration 61400 / 80000: loss 0.667494\n",
      "iteration 61500 / 80000: loss 0.753097\n",
      "train_acc 0.750000, val_acc 0.737000, time 42\n",
      "iteration 61600 / 80000: loss 0.753516\n",
      "iteration 61700 / 80000: loss 0.822769\n",
      "iteration 61800 / 80000: loss 0.736301\n",
      "train_acc 0.789062, val_acc 0.732000, time 42\n",
      "iteration 61900 / 80000: loss 0.726739\n",
      "iteration 62000 / 80000: loss 0.615264\n",
      "iteration 62100 / 80000: loss 0.650602\n",
      "iteration 62200 / 80000: loss 0.693256\n",
      "train_acc 0.773438, val_acc 0.743000, time 43\n",
      "iteration 62300 / 80000: loss 0.787721\n",
      "iteration 62400 / 80000: loss 0.597274\n",
      "iteration 62500 / 80000: loss 0.801313\n",
      "iteration 62600 / 80000: loss 0.687504\n",
      "train_acc 0.851562, val_acc 0.735000, time 43\n",
      "iteration 62700 / 80000: loss 0.806505\n",
      "iteration 62800 / 80000: loss 0.601890\n",
      "iteration 62900 / 80000: loss 0.716987\n",
      "iteration 63000 / 80000: loss 0.626658\n",
      "train_acc 0.812500, val_acc 0.744000, time 43\n",
      "iteration 63100 / 80000: loss 0.764623\n",
      "iteration 63200 / 80000: loss 0.685154\n",
      "iteration 63300 / 80000: loss 0.765029\n",
      "iteration 63400 / 80000: loss 0.848552\n",
      "train_acc 0.796875, val_acc 0.736000, time 43\n",
      "iteration 63500 / 80000: loss 0.626099\n",
      "iteration 63600 / 80000: loss 0.628553\n",
      "iteration 63700 / 80000: loss 0.657414\n",
      "train_acc 0.835938, val_acc 0.739000, time 44\n",
      "iteration 63800 / 80000: loss 0.743913\n",
      "iteration 63900 / 80000: loss 0.572494\n",
      "iteration 64000 / 80000: loss 0.674787\n",
      "iteration 64100 / 80000: loss 0.748048\n",
      "train_acc 0.757812, val_acc 0.733000, time 44\n",
      "iteration 64200 / 80000: loss 0.582590\n",
      "iteration 64300 / 80000: loss 0.785978\n",
      "iteration 64400 / 80000: loss 0.734989\n",
      "iteration 64500 / 80000: loss 0.605086\n",
      "train_acc 0.828125, val_acc 0.746000, time 44\n",
      "iteration 64600 / 80000: loss 0.732084\n",
      "iteration 64700 / 80000: loss 0.589615\n",
      "iteration 64800 / 80000: loss 0.740752\n",
      "iteration 64900 / 80000: loss 0.634041\n",
      "train_acc 0.773438, val_acc 0.738000, time 45\n",
      "iteration 65000 / 80000: loss 0.768359\n",
      "iteration 65100 / 80000: loss 0.589180\n",
      "iteration 65200 / 80000: loss 0.704133\n",
      "iteration 65300 / 80000: loss 0.783383\n",
      "train_acc 0.820312, val_acc 0.742000, time 45\n",
      "iteration 65400 / 80000: loss 0.727902\n",
      "iteration 65500 / 80000: loss 0.748257\n",
      "iteration 65600 / 80000: loss 0.818441\n",
      "iteration 65700 / 80000: loss 0.737120\n",
      "train_acc 0.781250, val_acc 0.746000, time 45\n",
      "iteration 65800 / 80000: loss 0.722466\n",
      "iteration 65900 / 80000: loss 0.739012\n",
      "iteration 66000 / 80000: loss 0.677234\n",
      "train_acc 0.773438, val_acc 0.727000, time 45\n",
      "iteration 66100 / 80000: loss 0.610528\n",
      "iteration 66200 / 80000: loss 0.750081\n",
      "iteration 66300 / 80000: loss 0.687872\n",
      "iteration 66400 / 80000: loss 0.692793\n",
      "train_acc 0.789062, val_acc 0.730000, time 46\n",
      "iteration 66500 / 80000: loss 0.672453\n",
      "iteration 66600 / 80000: loss 0.766262\n",
      "iteration 66700 / 80000: loss 0.624945\n",
      "iteration 66800 / 80000: loss 0.622017\n",
      "train_acc 0.804688, val_acc 0.735000, time 46\n",
      "iteration 66900 / 80000: loss 0.764961\n",
      "iteration 67000 / 80000: loss 0.667348\n",
      "iteration 67100 / 80000: loss 0.709631\n",
      "iteration 67200 / 80000: loss 0.713337\n",
      "train_acc 0.796875, val_acc 0.738000, time 46\n",
      "iteration 67300 / 80000: loss 0.794042\n",
      "iteration 67400 / 80000: loss 0.593402\n",
      "iteration 67500 / 80000: loss 0.743461\n",
      "iteration 67600 / 80000: loss 0.727853\n",
      "train_acc 0.804688, val_acc 0.731000, time 46\n",
      "iteration 67700 / 80000: loss 0.658863\n",
      "iteration 67800 / 80000: loss 0.632887\n",
      "iteration 67900 / 80000: loss 0.671057\n",
      "train_acc 0.835938, val_acc 0.727000, time 47\n",
      "iteration 68000 / 80000: loss 0.635233\n",
      "iteration 68100 / 80000: loss 0.719838\n",
      "iteration 68200 / 80000: loss 0.689353\n",
      "iteration 68300 / 80000: loss 0.763763\n",
      "train_acc 0.789062, val_acc 0.748000, time 47\n",
      "iteration 68400 / 80000: loss 0.677465\n",
      "iteration 68500 / 80000: loss 0.608456\n",
      "iteration 68600 / 80000: loss 0.661814\n",
      "iteration 68700 / 80000: loss 0.621795\n",
      "train_acc 0.804688, val_acc 0.737000, time 47\n",
      "iteration 68800 / 80000: loss 0.669220\n",
      "iteration 68900 / 80000: loss 0.710369\n",
      "iteration 69000 / 80000: loss 0.712330\n",
      "iteration 69100 / 80000: loss 0.646669\n",
      "train_acc 0.851562, val_acc 0.739000, time 47\n",
      "iteration 69200 / 80000: loss 0.679219\n",
      "iteration 69300 / 80000: loss 0.702477\n",
      "iteration 69400 / 80000: loss 0.513511\n",
      "iteration 69500 / 80000: loss 0.632451\n",
      "train_acc 0.859375, val_acc 0.736000, time 48\n",
      "iteration 69600 / 80000: loss 0.681248\n",
      "iteration 69700 / 80000: loss 0.726117\n",
      "iteration 69800 / 80000: loss 0.705305\n",
      "iteration 69900 / 80000: loss 0.716390\n",
      "train_acc 0.750000, val_acc 0.737000, time 48\n",
      "iteration 70000 / 80000: loss 0.729172\n",
      "iteration 70100 / 80000: loss 0.647640\n",
      "iteration 70200 / 80000: loss 0.655126\n",
      "train_acc 0.875000, val_acc 0.733000, time 48\n",
      "iteration 70300 / 80000: loss 0.691171\n",
      "iteration 70400 / 80000: loss 0.707813\n",
      "iteration 70500 / 80000: loss 0.742200\n",
      "iteration 70600 / 80000: loss 0.884157\n",
      "train_acc 0.828125, val_acc 0.742000, time 48\n",
      "iteration 70700 / 80000: loss 0.731867\n",
      "iteration 70800 / 80000: loss 0.726034\n",
      "iteration 70900 / 80000: loss 0.754176\n",
      "iteration 71000 / 80000: loss 0.762802\n",
      "train_acc 0.843750, val_acc 0.736000, time 49\n",
      "iteration 71100 / 80000: loss 0.677257\n",
      "iteration 71200 / 80000: loss 0.738511\n",
      "iteration 71300 / 80000: loss 0.871229\n",
      "iteration 71400 / 80000: loss 0.725639\n",
      "train_acc 0.828125, val_acc 0.734000, time 49\n",
      "iteration 71500 / 80000: loss 0.770579\n",
      "iteration 71600 / 80000: loss 0.683530\n",
      "iteration 71700 / 80000: loss 0.685471\n",
      "iteration 71800 / 80000: loss 0.727358\n",
      "train_acc 0.875000, val_acc 0.733000, time 49\n",
      "iteration 71900 / 80000: loss 0.605963\n",
      "iteration 72000 / 80000: loss 0.891365\n",
      "iteration 72100 / 80000: loss 0.806237\n",
      "train_acc 0.789062, val_acc 0.733000, time 50\n",
      "iteration 72200 / 80000: loss 0.699526\n",
      "iteration 72300 / 80000: loss 0.688667\n",
      "iteration 72400 / 80000: loss 0.767740\n",
      "iteration 72500 / 80000: loss 0.599457\n",
      "train_acc 0.835938, val_acc 0.739000, time 50\n",
      "iteration 72600 / 80000: loss 0.653660\n",
      "iteration 72700 / 80000: loss 0.716791\n",
      "iteration 72800 / 80000: loss 0.630564\n",
      "iteration 72900 / 80000: loss 0.551886\n",
      "train_acc 0.835938, val_acc 0.737000, time 50\n",
      "iteration 73000 / 80000: loss 0.624381\n",
      "iteration 73100 / 80000: loss 0.792582\n",
      "iteration 73200 / 80000: loss 0.598658\n",
      "iteration 73300 / 80000: loss 0.597124\n",
      "train_acc 0.789062, val_acc 0.739000, time 50\n",
      "iteration 73400 / 80000: loss 0.665871\n",
      "iteration 73500 / 80000: loss 0.720525\n",
      "iteration 73600 / 80000: loss 0.840638\n",
      "iteration 73700 / 80000: loss 0.646453\n",
      "train_acc 0.796875, val_acc 0.736000, time 51\n",
      "iteration 73800 / 80000: loss 0.737233\n",
      "iteration 73900 / 80000: loss 0.612631\n",
      "iteration 74000 / 80000: loss 0.586872\n",
      "iteration 74100 / 80000: loss 0.680560\n",
      "train_acc 0.796875, val_acc 0.743000, time 51\n",
      "iteration 74200 / 80000: loss 0.737555\n",
      "iteration 74300 / 80000: loss 0.678352\n",
      "iteration 74400 / 80000: loss 0.699259\n",
      "train_acc 0.804688, val_acc 0.736000, time 51\n",
      "iteration 74500 / 80000: loss 0.647250\n",
      "iteration 74600 / 80000: loss 0.671534\n",
      "iteration 74700 / 80000: loss 0.718196\n",
      "iteration 74800 / 80000: loss 0.639139\n",
      "train_acc 0.820312, val_acc 0.737000, time 51\n",
      "iteration 74900 / 80000: loss 0.666622\n",
      "iteration 75000 / 80000: loss 0.697507\n",
      "iteration 75100 / 80000: loss 0.785800\n",
      "iteration 75200 / 80000: loss 0.657237\n",
      "train_acc 0.843750, val_acc 0.741000, time 52\n",
      "iteration 75300 / 80000: loss 0.717779\n",
      "iteration 75400 / 80000: loss 0.765272\n",
      "iteration 75500 / 80000: loss 0.597796\n",
      "iteration 75600 / 80000: loss 0.849880\n",
      "train_acc 0.765625, val_acc 0.737000, time 52\n",
      "iteration 75700 / 80000: loss 0.584601\n",
      "iteration 75800 / 80000: loss 0.665576\n",
      "iteration 75900 / 80000: loss 0.768896\n",
      "iteration 76000 / 80000: loss 0.786336\n",
      "train_acc 0.750000, val_acc 0.735000, time 52\n",
      "iteration 76100 / 80000: loss 0.686907\n",
      "iteration 76200 / 80000: loss 0.728523\n",
      "iteration 76300 / 80000: loss 0.967068\n",
      "iteration 76400 / 80000: loss 0.689928\n",
      "train_acc 0.781250, val_acc 0.744000, time 52\n",
      "iteration 76500 / 80000: loss 0.642680\n",
      "iteration 76600 / 80000: loss 0.729964\n",
      "iteration 76700 / 80000: loss 0.766842\n",
      "train_acc 0.781250, val_acc 0.739000, time 53\n",
      "iteration 76800 / 80000: loss 0.541462\n",
      "iteration 76900 / 80000: loss 0.611498\n",
      "iteration 77000 / 80000: loss 0.831398\n",
      "iteration 77100 / 80000: loss 0.630097\n",
      "train_acc 0.773438, val_acc 0.746000, time 53\n",
      "iteration 77200 / 80000: loss 0.767998\n",
      "iteration 77300 / 80000: loss 0.531480\n",
      "iteration 77400 / 80000: loss 0.762684\n",
      "iteration 77500 / 80000: loss 0.686399\n",
      "train_acc 0.796875, val_acc 0.740000, time 53\n",
      "iteration 77600 / 80000: loss 0.655057\n",
      "iteration 77700 / 80000: loss 0.533089\n",
      "iteration 77800 / 80000: loss 0.735017\n",
      "iteration 77900 / 80000: loss 0.767542\n",
      "train_acc 0.820312, val_acc 0.742000, time 54\n",
      "iteration 78000 / 80000: loss 0.731228\n",
      "iteration 78100 / 80000: loss 0.557887\n",
      "iteration 78200 / 80000: loss 0.677763\n",
      "iteration 78300 / 80000: loss 0.649230\n",
      "train_acc 0.765625, val_acc 0.739000, time 54\n",
      "iteration 78400 / 80000: loss 0.611584\n",
      "iteration 78500 / 80000: loss 0.621391\n",
      "iteration 78600 / 80000: loss 0.647307\n",
      "train_acc 0.796875, val_acc 0.743000, time 54\n",
      "iteration 78700 / 80000: loss 0.668688\n",
      "iteration 78800 / 80000: loss 0.645592\n",
      "iteration 78900 / 80000: loss 0.571419\n",
      "iteration 79000 / 80000: loss 0.540247\n",
      "train_acc 0.804688, val_acc 0.730000, time 54\n",
      "iteration 79100 / 80000: loss 0.715366\n",
      "iteration 79200 / 80000: loss 0.770435\n",
      "iteration 79300 / 80000: loss 0.853190\n",
      "iteration 79400 / 80000: loss 0.696549\n",
      "train_acc 0.804688, val_acc 0.744000, time 55\n",
      "iteration 79500 / 80000: loss 0.639594\n",
      "iteration 79600 / 80000: loss 0.630231\n",
      "iteration 79700 / 80000: loss 0.695162\n",
      "iteration 79800 / 80000: loss 0.705914\n",
      "train_acc 0.804688, val_acc 0.744000, time 55\n",
      "iteration 79900 / 80000: loss 0.824870\n",
      "iteration 80000 / 80000: loss 0.735805\n",
      "Train accuracy:  0.802653061224\n",
      "Validation accuracy:  0.726\n"
     ]
    }
   ],
   "source": [
    "from neural_net import *\n",
    "import matplotlib.pyplot as plt\n",
    "input_size = trainXC.shape[1]\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# In[126]:\n",
    "import os.path\n",
    "if not os.path.isfile(\"feats.csv\"):\n",
    "    with open(\"feats.csv\",\"w\") as f:\n",
    "        f.write(\"hidden_size,momentum,dropout,learning_rate,learning_rate_decay\"+'\\n')\n",
    "\n",
    "hidden_size=200\n",
    "momentum=.95\n",
    "learning_rate=5e-4\n",
    "learning_rate_decay=.99\n",
    "dropout=.3\n",
    "\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes,1e-4)\n",
    "stats = net.train(trainXC, y_train, valXC, y_val,\n",
    "                        num_iters=70000, batch_size=128,\n",
    "                        learning_rate=learning_rate, learning_rate_decay=learning_rate_decay,\n",
    "                        reg=0, verbose=True,update=\"momentum\",arg=momentum,dropout=dropout)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (net.predict(trainXC) == y_train).mean()\n",
    "print 'Train accuracy: ', val_acc\n",
    "val_acc = (net.predict(valXC) == y_val).mean()\n",
    "print 'Validation accuracy: ', val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 15000: loss 2.228800\n",
      "iteration 200 / 15000: loss 1.865953\n",
      "iteration 300 / 15000: loss 1.813429\n",
      "train_acc 0.359375, val_acc 0.391000, time 4\n",
      "iteration 400 / 15000: loss 1.841293\n",
      "iteration 500 / 15000: loss 1.534809\n",
      "iteration 600 / 15000: loss 1.483581\n",
      "iteration 700 / 15000: loss 1.336817\n",
      "train_acc 0.531250, val_acc 0.491000, time 9\n",
      "iteration 800 / 15000: loss 1.461629\n",
      "iteration 900 / 15000: loss 1.508736\n",
      "iteration 1000 / 15000: loss 1.163824\n",
      "iteration 1100 / 15000: loss 1.354160\n",
      "train_acc 0.570312, val_acc 0.545000, time 14\n",
      "iteration 1200 / 15000: loss 1.259659\n",
      "iteration 1300 / 15000: loss 1.479382\n",
      "iteration 1400 / 15000: loss 1.186748\n",
      "iteration 1500 / 15000: loss 1.349476\n",
      "train_acc 0.468750, val_acc 0.561000, time 20\n",
      "iteration 1600 / 15000: loss 1.422179\n",
      "iteration 1700 / 15000: loss 1.201795\n",
      "iteration 1800 / 15000: loss 1.474555\n",
      "iteration 1900 / 15000: loss 1.094366\n",
      "train_acc 0.476562, val_acc 0.573000, time 23\n",
      "iteration 2000 / 15000: loss 1.233943\n",
      "iteration 2100 / 15000: loss 1.210773\n",
      "iteration 2200 / 15000: loss 1.117206\n",
      "train_acc 0.562500, val_acc 0.594000, time 27\n",
      "iteration 2300 / 15000: loss 1.381386\n",
      "iteration 2400 / 15000: loss 1.166435\n",
      "iteration 2500 / 15000: loss 1.156002\n",
      "iteration 2600 / 15000: loss 1.051123\n",
      "train_acc 0.601562, val_acc 0.599000, time 30\n",
      "iteration 2700 / 15000: loss 1.233492\n",
      "iteration 2800 / 15000: loss 1.078157\n",
      "iteration 2900 / 15000: loss 1.136730\n",
      "iteration 3000 / 15000: loss 0.986995\n",
      "train_acc 0.617188, val_acc 0.604000, time 34\n",
      "iteration 3100 / 15000: loss 1.132000\n",
      "iteration 3200 / 15000: loss 1.138462\n",
      "iteration 3300 / 15000: loss 1.182975\n",
      "iteration 3400 / 15000: loss 1.178325\n",
      "train_acc 0.640625, val_acc 0.604000, time 37\n",
      "iteration 3500 / 15000: loss 1.194806\n",
      "iteration 3600 / 15000: loss 1.191540\n",
      "iteration 3700 / 15000: loss 1.143066\n",
      "iteration 3800 / 15000: loss 1.230856\n",
      "train_acc 0.609375, val_acc 0.613000, time 40\n",
      "iteration 3900 / 15000: loss 1.158274\n",
      "iteration 4000 / 15000: loss 1.060990\n",
      "iteration 4100 / 15000: loss 1.151808\n",
      "iteration 4200 / 15000: loss 1.159805\n",
      "train_acc 0.718750, val_acc 0.606000, time 44\n",
      "iteration 4300 / 15000: loss 1.228290\n",
      "iteration 4400 / 15000: loss 1.125951\n",
      "iteration 4500 / 15000: loss 1.023641\n",
      "train_acc 0.664062, val_acc 0.624000, time 47\n",
      "iteration 4600 / 15000: loss 1.229601\n",
      "iteration 4700 / 15000: loss 1.065055\n",
      "iteration 4800 / 15000: loss 1.016254\n",
      "iteration 4900 / 15000: loss 1.023399\n",
      "train_acc 0.710938, val_acc 0.632000, time 50\n",
      "iteration 5000 / 15000: loss 1.149799\n",
      "iteration 5100 / 15000: loss 1.116200\n",
      "iteration 5200 / 15000: loss 1.124071\n",
      "iteration 5300 / 15000: loss 1.089613\n",
      "train_acc 0.562500, val_acc 0.637000, time 54\n",
      "iteration 5400 / 15000: loss 0.974313\n",
      "iteration 5500 / 15000: loss 1.126423\n",
      "iteration 5600 / 15000: loss 1.154233\n",
      "iteration 5700 / 15000: loss 1.088650\n",
      "train_acc 0.593750, val_acc 0.643000, time 57\n",
      "iteration 5800 / 15000: loss 1.028226\n",
      "iteration 5900 / 15000: loss 1.158712\n",
      "iteration 6000 / 15000: loss 1.026530\n",
      "iteration 6100 / 15000: loss 1.056348\n",
      "train_acc 0.625000, val_acc 0.646000, time 60\n",
      "iteration 6200 / 15000: loss 1.057159\n",
      "iteration 6300 / 15000: loss 0.974386\n",
      "iteration 6400 / 15000: loss 0.937835\n",
      "train_acc 0.750000, val_acc 0.650000, time 64\n",
      "iteration 6500 / 15000: loss 0.943476\n",
      "iteration 6600 / 15000: loss 1.136730\n",
      "iteration 6700 / 15000: loss 1.040972\n",
      "iteration 6800 / 15000: loss 1.058443\n",
      "train_acc 0.664062, val_acc 0.655000, time 67\n",
      "iteration 6900 / 15000: loss 0.868746\n",
      "iteration 7000 / 15000: loss 0.822824\n",
      "iteration 7100 / 15000: loss 1.137407\n",
      "iteration 7200 / 15000: loss 0.885385\n",
      "train_acc 0.687500, val_acc 0.647000, time 70\n",
      "iteration 7300 / 15000: loss 0.880590\n",
      "iteration 7400 / 15000: loss 1.039905\n",
      "iteration 7500 / 15000: loss 1.011912\n",
      "iteration 7600 / 15000: loss 1.127931\n",
      "train_acc 0.695312, val_acc 0.673000, time 74\n",
      "iteration 7700 / 15000: loss 1.022487\n",
      "iteration 7800 / 15000: loss 1.047794\n",
      "iteration 7900 / 15000: loss 1.017711\n",
      "iteration 8000 / 15000: loss 0.969428\n",
      "train_acc 0.726562, val_acc 0.671000, time 77\n",
      "iteration 8100 / 15000: loss 0.999691\n",
      "iteration 8200 / 15000: loss 1.033162\n",
      "iteration 8300 / 15000: loss 1.023800\n",
      "iteration 8400 / 15000: loss 0.962012\n",
      "train_acc 0.593750, val_acc 0.674000, time 81\n",
      "iteration 8500 / 15000: loss 0.875089\n",
      "iteration 8600 / 15000: loss 0.824931\n",
      "iteration 8700 / 15000: loss 0.927520\n",
      "train_acc 0.726562, val_acc 0.669000, time 84\n",
      "iteration 8800 / 15000: loss 0.914531\n",
      "iteration 8900 / 15000: loss 0.849600\n",
      "iteration 9000 / 15000: loss 0.850175\n",
      "iteration 9100 / 15000: loss 0.992343\n",
      "train_acc 0.640625, val_acc 0.664000, time 88\n",
      "iteration 9200 / 15000: loss 0.974157\n",
      "iteration 9300 / 15000: loss 0.850525\n",
      "iteration 9400 / 15000: loss 0.822269\n",
      "iteration 9500 / 15000: loss 1.057659\n",
      "train_acc 0.718750, val_acc 0.653000, time 91\n",
      "iteration 9600 / 15000: loss 0.997555\n",
      "iteration 9700 / 15000: loss 1.008870\n",
      "iteration 9800 / 15000: loss 1.057199\n",
      "iteration 9900 / 15000: loss 1.077628\n",
      "train_acc 0.687500, val_acc 0.680000, time 94\n",
      "iteration 10000 / 15000: loss 0.992972\n",
      "iteration 10100 / 15000: loss 0.887109\n",
      "iteration 10200 / 15000: loss 0.781769\n",
      "iteration 10300 / 15000: loss 0.947490\n",
      "train_acc 0.726562, val_acc 0.668000, time 98\n",
      "iteration 10400 / 15000: loss 0.908332\n",
      "iteration 10500 / 15000: loss 0.923751\n",
      "iteration 10600 / 15000: loss 0.796561\n",
      "train_acc 0.710938, val_acc 0.680000, time 101\n",
      "iteration 10700 / 15000: loss 0.826473\n",
      "iteration 10800 / 15000: loss 0.879193\n",
      "iteration 10900 / 15000: loss 0.889710\n",
      "iteration 11000 / 15000: loss 0.848626\n",
      "train_acc 0.687500, val_acc 0.679000, time 105\n",
      "iteration 11100 / 15000: loss 0.903926\n",
      "iteration 11200 / 15000: loss 1.138004\n",
      "iteration 11300 / 15000: loss 0.876676\n",
      "iteration 11400 / 15000: loss 0.909138\n",
      "train_acc 0.679688, val_acc 0.673000, time 108\n",
      "iteration 11500 / 15000: loss 0.895081\n",
      "iteration 11600 / 15000: loss 0.861597\n",
      "iteration 11700 / 15000: loss 1.157845\n",
      "iteration 11800 / 15000: loss 0.990209\n",
      "train_acc 0.656250, val_acc 0.695000, time 112\n",
      "iteration 11900 / 15000: loss 0.893353\n",
      "iteration 12000 / 15000: loss 0.750755\n",
      "iteration 12100 / 15000: loss 0.827303\n",
      "iteration 12200 / 15000: loss 0.954702\n",
      "train_acc 0.710938, val_acc 0.695000, time 115\n",
      "iteration 12300 / 15000: loss 0.831285\n",
      "iteration 12400 / 15000: loss 0.900263\n",
      "iteration 12500 / 15000: loss 0.804226\n",
      "iteration 12600 / 15000: loss 0.995109\n",
      "train_acc 0.718750, val_acc 0.698000, time 119\n",
      "iteration 12700 / 15000: loss 0.856005\n",
      "iteration 12800 / 15000: loss 0.834081\n",
      "iteration 12900 / 15000: loss 0.887052\n",
      "train_acc 0.750000, val_acc 0.678000, time 122\n",
      "iteration 13000 / 15000: loss 0.940602\n",
      "iteration 13100 / 15000: loss 0.922677\n",
      "iteration 13200 / 15000: loss 0.996318\n",
      "iteration 13300 / 15000: loss 0.790748\n",
      "train_acc 0.726562, val_acc 0.691000, time 125\n",
      "iteration 13400 / 15000: loss 1.040650\n",
      "iteration 13500 / 15000: loss 0.924309\n",
      "iteration 13600 / 15000: loss 0.983422\n",
      "iteration 13700 / 15000: loss 0.738111\n",
      "train_acc 0.687500, val_acc 0.702000, time 129\n",
      "iteration 13800 / 15000: loss 0.766118\n",
      "iteration 13900 / 15000: loss 0.878795\n",
      "iteration 14000 / 15000: loss 0.852108\n",
      "iteration 14100 / 15000: loss 0.850525\n",
      "train_acc 0.726562, val_acc 0.697000, time 132\n",
      "iteration 14200 / 15000: loss 0.802646\n",
      "iteration 14300 / 15000: loss 0.937250\n",
      "iteration 14400 / 15000: loss 0.786440\n",
      "iteration 14500 / 15000: loss 0.795184\n",
      "train_acc 0.742188, val_acc 0.700000, time 136\n",
      "iteration 14600 / 15000: loss 0.901027\n",
      "iteration 14700 / 15000: loss 0.893916\n",
      "iteration 14800 / 15000: loss 1.122639\n",
      "train_acc 0.679688, val_acc 0.696000, time 139\n",
      "iteration 14900 / 15000: loss 0.712603\n",
      "iteration 15000 / 15000: loss 0.883354\n",
      "Train accuracy:  0.727959183673\n",
      "Validation accuracy:  0.704\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5a9c0585c5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feats.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtune\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate_decay\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "f=open(\"feats.csv\",\"a\")\n",
    "tune=[hidden_size,momentum,dropout,learning_rate,learning_rate_decay]\n",
    "f.write(str(tune+[train_acc,val_acc]).strip(\"[]\")+'\\n')\n",
    "f.close()\n",
    "with open(\"feats/\"+ str([val_acc]+tune).strip(\"[]\")+'.pickle','w') as f:\n",
    "    pickle.dump(stats,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fcd9aa12690>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the loss function and train / validation accuracies\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.savefig(\"./report/kmeans_his.eps\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.savefig('./report/kmeans_acc.eps')\n",
    "plt.show()\n",
    "plt.ylabel('Clasification accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=1000\n",
    "momentum=.9\n",
    "learning_rate=1e-3\n",
    "learning_rate_decay=.99\n",
    "reg=.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
